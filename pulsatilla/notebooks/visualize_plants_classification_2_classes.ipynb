{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UJe9Wj8q0JYA",
        "F78rduht0PKm",
        "G_fvoecWPh6i"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "n9yayXbcId-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек"
      ],
      "metadata": {
        "id": "UJe9Wj8q0JYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torchvision.transforms.v2 as v2\n",
        "import torchvision.transforms as T\n",
        "import PIL\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "2PuDjxHZ0Mly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import softmax\n",
        "import random\n",
        "import cv2\n",
        "from torchvision import models\n"
      ],
      "metadata": {
        "id": "2BNabJnePxV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pytorch_grad_cam import GradCAM, GradCAMPlusPlus\n",
        "# from pytorch_grad_cam.utils.model_targets import ClassifierOutputSoftmaxTarget\n",
        "# from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image"
      ],
      "metadata": {
        "id": "4hCgOGWTJEat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Set seed\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "Xf6vpU0bGKYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Важные переменные"
      ],
      "metadata": {
        "id": "F78rduht0PKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtVMgI1y1W9v",
        "outputId": "96000869-721d-4dae-dcf0-3c859d97bae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class1_folder = '/content/drive/MyDrive/plants_classification/P. multifida'\n",
        "class2_folder = '/content/drive/MyDrive/plants_classification/P. turczaninovii'\n",
        "hybrid_class_folder = '/content/drive/MyDrive/plants_classification/Hybrid'\n",
        "project_folder = '/content/drive/MyDrive/plants_classification'"
      ],
      "metadata": {
        "id": "5pWVN_-t0YEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_save_path = \"/content/drive/MyDrive/plants_classification/models/best_model_resnet50_no_shuffle_ext_500ep.pth\""
      ],
      "metadata": {
        "id": "PknRM3jRdahM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Работа с данными"
      ],
      "metadata": {
        "id": "GYqNp9rU4Xn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функции"
      ],
      "metadata": {
        "id": "G_fvoecWPh6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an image and preprocess it\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "    img = cv2.resize(img, (224, 224))  # Resize for MobileNetV2\n",
        "    img = transforms.ToTensor()(img)\n",
        "    img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "    img = img.unsqueeze(0)  # Add batch dimension\n",
        "    return img\n",
        "\n",
        "# Function to get the class label\n",
        "def get_class_label(preds):\n",
        "    _, class_index = torch.max(preds, 1)\n",
        "    return class_index.item()\n",
        "\n",
        "def get_conv_layer(model, conv_layer_name):\n",
        "    for name, layer in model.named_modules():\n",
        "        if name == conv_layer_name:\n",
        "            return layer\n",
        "    raise ValueError(f\"Layer '{conv_layer_name}' not found in the model.\")\n",
        "\n",
        "# Function to generate Grad-CAM heatmap\n",
        "def compute_gradcam(model, img_tensor, class_index, conv_layer_name=\"layer4\"):\n",
        "    conv_layer = get_conv_layer(model, conv_layer_name)\n",
        "\n",
        "    # Forward hook to store activations\n",
        "    activations = None\n",
        "    def forward_hook(module, input, output):\n",
        "        nonlocal activations\n",
        "        activations = output\n",
        "\n",
        "    hook = conv_layer.register_forward_hook(forward_hook)\n",
        "\n",
        "    # Compute gradients\n",
        "    img_tensor.requires_grad_(True)\n",
        "    preds = model(img_tensor)\n",
        "    loss = preds[:, class_index]\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Get gradients\n",
        "    grads = img_tensor.grad.cpu().numpy()\n",
        "    pooled_grads = np.mean(grads, axis=(0, 2, 3))\n",
        "\n",
        "    # Remove the hook\n",
        "    hook.remove()\n",
        "\n",
        "    activations = activations.detach().cpu().numpy()[0]\n",
        "    for i in range(pooled_grads.shape[0]):\n",
        "        activations[i, ...] *= pooled_grads[i]\n",
        "\n",
        "    heatmap = np.mean(activations, axis=0)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "# Overlay heatmap on image\n",
        "def overlay_heatmap(img_path, heatmap, alpha=0.4):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "    superimposed_img = cv2.addWeighted(img, alpha, heatmap, 1 - alpha, 0)\n",
        "    return superimposed_img\n",
        "\n",
        "def get_grad_cam(img_path, out_name):\n",
        "  global model\n",
        "  # Example Usage\n",
        "  img_tensor = preprocess_image(img_path)\n",
        "\n",
        "  # Get model predictions\n",
        "  with torch.no_grad():\n",
        "      preds = model(img_tensor)\n",
        "  class_index = get_class_label(preds)\n",
        "  preds = softmax(preds)\n",
        "  print(f\"Вероятность принадлежности экземпляра к P. multifida: {preds[0][0]:.3f}\")\n",
        "  print(f\"Вероятность принадлежности экземпляра к P. turczaninovii: {preds[0][1]:.3f}\")\n",
        "  print(f\"Predicted Class Index: {class_index}\")\n",
        "\n",
        "  # Compute Grad-CAM heatmap\n",
        "  heatmap = compute_gradcam(model, img_tensor, class_index)\n",
        "\n",
        "\n",
        "  # Overlay heatmap on the original image\n",
        "  output_img = overlay_heatmap(img_path, heatmap)\n",
        "\n",
        "  # Save the heatmap\n",
        "  cv2.imwrite(out_name, output_img)"
      ],
      "metadata": {
        "id": "BuZSYRLYPluA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Преобразование меток"
      ],
      "metadata": {
        "id": "O0YBu9eN_1io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annot_df = pd.read_csv('/content/drive/MyDrive/plants_classification/annotations.csv', index_col=0)"
      ],
      "metadata": {
        "id": "EOjDhiKNeb3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annot_df['target'] = annot_df['target'].map({'P. multifida': 0, 'P. turczaninovii': 1})"
      ],
      "metadata": {
        "id": "GbqM_uM__8bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_imgs = annot_df.loc[annot_df['mode'] == 'test', ['name', 'target']]\n",
        "test_multifida = test_imgs[test_imgs.target == 0].name.values\n",
        "test_turczaninovii = test_imgs[test_imgs.target == 1].name.values"
      ],
      "metadata": {
        "id": "2r5rQRDt7ahL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель"
      ],
      "metadata": {
        "id": "NjcQqCbmQoj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_img_preprocessing = v2.Compose([\n",
        "        T.Resize((224, 224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])"
      ],
      "metadata": {
        "id": "iKErdm6v0CI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet50(weights=\"DEFAULT\")\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(model_save_path, map_location=device), strict=False)\n",
        "model.to(device)\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "jKgR_S_qPaJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258fc5d5-6a50-4697-cee0-a7c246420893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 73.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ywwWn95VSY9",
        "outputId": "84b52b89-6285-4356-c987-4ac70abcf858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Свертки"
      ],
      "metadata": {
        "id": "KB5zpezbzm-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.layer1.named_children())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItryZfOtDhgo",
        "outputId": "d0cbc62c-1485-4c9a-f644-58956e8289c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('0',\n",
              "  Bottleneck(\n",
              "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (downsample): Sequential(\n",
              "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )),\n",
              " ('1',\n",
              "  Bottleneck(\n",
              "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "  )),\n",
              " ('2',\n",
              "  Bottleneck(\n",
              "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "  ))]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [model.layer1, model.layer2, model.layer3, model.layer4]\n",
        "chosen_layers = []\n",
        "for i, layer in enumerate(layers):\n",
        "  for j in range(len(list(layer.named_children()))):\n",
        "    name = f'Layer {i+1} Bottleneck {j} '\n",
        "    chosen_layers.append({'name': name + 'Conv1',\n",
        "                           'layer': layer[j].conv1})\n",
        "    chosen_layers.append({'name': name + 'Conv2',\n",
        "                           'layer': layer[j].conv2})\n",
        "    chosen_layers.append({'name': name + 'Conv3',\n",
        "                           'layer': layer[j].conv3})"
      ],
      "metadata": {
        "id": "5EF0K-uiXajn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = test_multifida[3] # Замените на путь к вашему изображению\n",
        "image = Image.open(image_path)\n",
        "input_batch = preprocess_image(image_path)\n",
        "layer_activations = {}  # Словарь для хранения активаций\n",
        "visual_map = {64: (8, 8),\n",
        "              128: (16, 8),\n",
        "              256: (16, 16),\n",
        "              512: (32, 16),\n",
        "              1024: (32, 32),\n",
        "              2048: (64, 32)}"
      ],
      "metadata": {
        "id": "j9rTIXTseHbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        layer_activations[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "# def visualize_activations(activations, layer_name):\n",
        "#     # Визуализация карт признаков (feature maps) для данного слоя\n",
        "#     num_filters = activations.shape[1]\n",
        "#     nxdim, nydim = visual_map[num_filters]\n",
        "#     fig, axes = plt.subplots(nxdim, nydim)\n",
        "#     for i in range(nxdim):\n",
        "#       for j in range(nydim):\n",
        "#         ax = axes[i, j]\n",
        "#         ax.imshow(activations[0, i * nydim + j].cpu().numpy(), cmap='gray') # Отображение как grayscale image\n",
        "#         ax.axis('off') # Отключаем оси\n",
        "#     fig.suptitle(layer_name)\n",
        "#     fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "#     return fig\n",
        "\n",
        "for pair in chosen_layers:\n",
        "  pair['layer'].register_forward_hook(get_activation(pair['name']))\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "\n",
        "# for pair in chosen_layers:\n",
        "#     activations = layer_activations[pair['name']]\n",
        "#     fig = visualize_activations(activations, pair['name'])\n",
        "#     plt.savefig(f'/content/drive/MyDrive/plants_classification/cnn_shots/multifida_{pair[\"name\"]}.jpg')\n",
        "#     plt.close(fig)\n",
        "\n",
        "# # 7. Создание кадров для GIF:\n",
        "# frames = []\n",
        "\n",
        "# # Кадр 1: Исходное изображение\n",
        "# fig_original, ax_original = plt.subplots()\n",
        "# ax_original.imshow(image)\n",
        "# ax_original.axis('off')\n",
        "# plt.savefig('frame_1.jpg')\n",
        "# plt.close(fig_original)"
      ],
      "metadata": {
        "id": "tJJEvKC9h9Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for (name, image_path) in\n",
        "for pair in chosen_layers:\n",
        "    activations = layer_activations[pair['name']]\n",
        "    path = \"/content/drive/MyDrive/plants_classification/cnn_gif_folders/multifida/data/\" + f'{pair[\"name\"]} filter_{1}.jpg'\n",
        "    num_filters = activations.shape[1]\n",
        "    fig, ax = plt.subplots()  # Создаем фигуру и оси один раз\n",
        "    ax.imshow(activations[0, 0].cpu().numpy(), cmap='gray')\n",
        "    ax.axis('off')\n",
        "    ax.set_title(pair['name'] + f' Filter {1}')\n",
        "    fig.savefig(path)  # Сохраняем фигуру\n",
        "    ax.clear() # Очищаем оси для следующего фильтра\n",
        "    plt.close(fig)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FXhDvZjQW3iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()  # Создаем фигуру и оси один раз\n",
        "ax.imshow(image)\n",
        "ax.axis('off')\n",
        "ax.set_title('Source image. P. multifida')\n",
        "fig.savefig(path)  # Сохраняем фигуру\n",
        "ax.clear() # Очищаем оси для следующего фильтра\n",
        "plt.close(fig)"
      ],
      "metadata": {
        "id": "BYhBMJDLxEwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/plants_classification/cnn_gif_folders/multifida/data/\" + f'source.jpg'\n"
      ],
      "metadata": {
        "id": "DS6tzw5Jwx5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grad-Cam"
      ],
      "metadata": {
        "id": "JEuplG5AUj3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(5):\n",
        "#   get_grad_cam(test_multifida[i], f'/content/drive/MyDrive/plants_classification/grad_cam_results/multifida_{i}.jpg')\n",
        "#   get_grad_cam(test_turczaninovii[i], f'/content/drive/MyDrive/plants_classification/grad_cam_results/turczaninovii_{i}.jpg')"
      ],
      "metadata": {
        "id": "zyJHxWVEapIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# # ----------------------------------------------------------------------\n",
        "# # 3. Define Transformations\n",
        "# # ----------------------------------------------------------------------\n",
        "\n",
        "# # Define image transformations, including resizing\n",
        "# image_size = (224, 224)  # Grad-CAM often works best with a fixed size\n",
        "\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize(image_size),  # Resize the image\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "# ])\n",
        "\n",
        "# targets = [ClassifierOutputSoftmaxTarget(1)]\n",
        "# # fix the target layer (after which we'd like to generate the CAM)\n",
        "# target_layers = [model.layer4]\n",
        "# cam = GradCAM(model=model, target_layers=target_layers) # Ensure CUDA is used if available\n",
        "\n",
        "\n",
        "\n",
        "# print(input_tensor.size())\n",
        "# # generate CAM\n",
        "# grayscale_cams = cam(input_tensor=input_tensor, targets=targets)\n",
        "# cam_image = show_cam_on_image(np.float32(img)/255, grayscale_cams[0, :], use_rgb=True) # Convert PIL Image to numpy array and normalize\n",
        "# cam_image = np.uint8(255 * cam_image)  # Convert back to uint8\n",
        "\n",
        "# cam = np.uint8(255*grayscale_cams[0, :])\n",
        "# cam = cv2.merge([cam, cam, cam])\n",
        "\n",
        "# # Convert PIL Image to numpy array\n",
        "# img_np = np.array(img)\n",
        "\n",
        "# # Resize cam_image to match the dimensions of img_np\n",
        "# cam_image_resized = cv2.resize(cam_image, (img_np.shape[1], img_np.shape[0])) # (width, height)\n",
        "\n",
        "# # display the original image & the associated CAM\n",
        "# images = np.hstack((img_np, cam_image_resized))\n",
        "# final_image = PIL.Image.fromarray(images)\n",
        "# final_image.show() # Or save it"
      ],
      "metadata": {
        "id": "2KItrE6eCEga"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}