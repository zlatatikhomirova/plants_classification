{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UJe9Wj8q0JYA",
        "F78rduht0PKm",
        "G_fvoecWPh6i"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "n9yayXbcId-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек"
      ],
      "metadata": {
        "id": "UJe9Wj8q0JYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torchvision.transforms.v2 as v2\n",
        "import torchvision.transforms as T\n",
        "import PIL\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "2PuDjxHZ0Mly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import softmax\n",
        "import random\n",
        "import cv2\n",
        "from torchvision import models\n"
      ],
      "metadata": {
        "id": "2BNabJnePxV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pytorch_grad_cam import GradCAM, GradCAMPlusPlus\n",
        "# from pytorch_grad_cam.utils.model_targets import ClassifierOutputSoftmaxTarget\n",
        "# from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image"
      ],
      "metadata": {
        "id": "4hCgOGWTJEat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Set seed\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "Xf6vpU0bGKYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Важные переменные"
      ],
      "metadata": {
        "id": "F78rduht0PKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtVMgI1y1W9v",
        "outputId": "4174bf5a-3f92-44b0-9361-975be4cdcafb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class1_folder = '/content/drive/MyDrive/plants_classification/P. multifida'\n",
        "class2_folder = '/content/drive/MyDrive/plants_classification/P. turczaninovii'\n",
        "hybrid_class_folder = '/content/drive/MyDrive/plants_classification/Hybrid'\n",
        "project_folder = '/content/drive/MyDrive/plants_classification'"
      ],
      "metadata": {
        "id": "5pWVN_-t0YEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# model_save_path = \"/content/drive/MyDrive/plants_classification/models/best_model_resnet50_no_shuffle_ext_500ep.pth\""
      ],
      "metadata": {
        "id": "PknRM3jRdahM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Работа с данными"
      ],
      "metadata": {
        "id": "GYqNp9rU4Xn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функции"
      ],
      "metadata": {
        "id": "G_fvoecWPh6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an image and preprocess it\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "    img = cv2.resize(img, (224, 224))  # Resize for MobileNetV2\n",
        "    img = transforms.ToTensor()(img)\n",
        "    img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
        "    img = img.unsqueeze(0)  # Add batch dimension\n",
        "    return img\n",
        "\n",
        "# Function to get the class label\n",
        "def get_class_label(preds):\n",
        "    _, class_index = torch.max(preds, 1)\n",
        "    return class_index.item()\n",
        "\n",
        "def get_conv_layer(model, conv_layer_name):\n",
        "    for name, layer in model.named_modules():\n",
        "        if name == conv_layer_name:\n",
        "            return layer\n",
        "    raise ValueError(f\"Layer '{conv_layer_name}' not found in the model.\")\n",
        "\n",
        "# Function to generate Grad-CAM heatmap\n",
        "def compute_gradcam(model, img_tensor, class_index, conv_layer_name=\"layer4\"):\n",
        "    conv_layer = get_conv_layer(model, conv_layer_name)\n",
        "\n",
        "    # Forward hook to store activations\n",
        "    activations = None\n",
        "    def forward_hook(module, input, output):\n",
        "        nonlocal activations\n",
        "        activations = output\n",
        "\n",
        "    hook = conv_layer.register_forward_hook(forward_hook)\n",
        "\n",
        "    # Compute gradients\n",
        "    img_tensor.requires_grad_(True)\n",
        "    preds = model(img_tensor)\n",
        "    loss = preds[:, class_index]\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Get gradients\n",
        "    grads = img_tensor.grad.cpu().numpy()\n",
        "    pooled_grads = np.mean(grads, axis=(0, 2, 3))\n",
        "\n",
        "    # Remove the hook\n",
        "    hook.remove()\n",
        "\n",
        "    activations = activations.detach().cpu().numpy()[0]\n",
        "    for i in range(pooled_grads.shape[0]):\n",
        "        activations[i, ...] *= pooled_grads[i]\n",
        "\n",
        "    heatmap = np.mean(activations, axis=0)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "# Overlay heatmap on image\n",
        "def overlay_heatmap(img_path, heatmap, alpha=0.4):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "    superimposed_img = cv2.addWeighted(img, alpha, heatmap, 1 - alpha, 0)\n",
        "    return superimposed_img\n",
        "\n",
        "def get_grad_cam(name, img_path, out_name, model):\n",
        "  # Example Usage\n",
        "  img_tensor = preprocess_image(img_path)\n",
        "\n",
        "  # Get model predictions\n",
        "  with torch.no_grad():\n",
        "      preds = model(img_tensor)\n",
        "  class_index = get_class_label(preds)\n",
        "  preds = softmax(preds)\n",
        "  print(f\"Вероятность принадлежности экземпляра к P. {name}: {preds[0][1]:.3f}\")\n",
        "  # print(f\"Predicted Class Index: {class_index}\")\n",
        "\n",
        "  # Compute Grad-CAM heatmap\n",
        "  heatmap = compute_gradcam(model, img_tensor, class_index)\n",
        "\n",
        "\n",
        "  # Overlay heatmap on the original image\n",
        "  output_img = overlay_heatmap(img_path, heatmap)\n",
        "\n",
        "  # Save the heatmap\n",
        "  cv2.imwrite(out_name, output_img)"
      ],
      "metadata": {
        "id": "BuZSYRLYPluA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Преобразование меток"
      ],
      "metadata": {
        "id": "O0YBu9eN_1io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annot_df = pd.read_csv('/content/drive/MyDrive/plants_classification/annotations_3_classes.csv', index_col=0)"
      ],
      "metadata": {
        "id": "EOjDhiKNeb3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annot_df = annot_df.drop(columns=['mode'])\n",
        "\n",
        "df_multifida = annot_df.copy()\n",
        "df_turczaninovii = annot_df.copy()\n",
        "df_hybrid = annot_df.copy()\n",
        "\n",
        "df_multifida['target'] = df_multifida['target'].map({'P. multifida': 1, 'P. turczaninovii': 0, 'Hybrid': 0})\n",
        "df_turczaninovii['target'] = df_turczaninovii['target'].map({'P. multifida': 0, 'P. turczaninovii': 1, 'Hybrid': 0})\n",
        "df_hybrid['target'] = df_hybrid['target'].map({'P. multifida': 0, 'P. turczaninovii': 0, 'Hybrid': 1})"
      ],
      "metadata": {
        "id": "GbqM_uM__8bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multifida_imgs = df_multifida[df_multifida.target == 1].name.values\n",
        "turczaninovii_imgs = df_turczaninovii[df_turczaninovii.target == 1].name.values\n",
        "hybrid_imgs = df_hybrid[df_hybrid.target == 1].name.values"
      ],
      "metadata": {
        "id": "2r5rQRDt7ahL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель"
      ],
      "metadata": {
        "id": "NjcQqCbmQoj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_img_preprocessing = v2.Compose([\n",
        "        T.Resize((224, 224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])"
      ],
      "metadata": {
        "id": "iKErdm6v0CI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(model_save_path):\n",
        "  model = torchvision.models.resnet50(weights=\"DEFAULT\")\n",
        "  for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "  for param in model.fc.parameters():\n",
        "      param.requires_grad = True\n",
        "  model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model.load_state_dict(torch.load(model_save_path, map_location=device), strict=False)\n",
        "  model.to(device)\n",
        "  model.eval();\n",
        "  return model"
      ],
      "metadata": {
        "id": "jKgR_S_qPaJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Свертки"
      ],
      "metadata": {
        "id": "KB5zpezbzm-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_layers(model):\n",
        "  layers = [model.layer1, model.layer2, model.layer3, model.layer4]\n",
        "  chosen_layers = []\n",
        "  for i, layer in enumerate(layers):\n",
        "    for j in range(len(list(layer.named_children()))):\n",
        "      name = f'Layer {i+1} Bottleneck {j} '\n",
        "      chosen_layers.append({'name': name + 'Conv1',\n",
        "                            'layer': layer[j].conv1})\n",
        "      chosen_layers.append({'name': name + 'Conv2',\n",
        "                            'layer': layer[j].conv2})\n",
        "      chosen_layers.append({'name': name + 'Conv3',\n",
        "                            'layer': layer[j].conv3})\n",
        "  return chosen_layers"
      ],
      "metadata": {
        "id": "lqD_ZcGWW_al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_multifida_path = '/content/drive/MyDrive/plants_classification/models/resnet50_ovr_multifida.pth'\n",
        "model_turczaninovii_path = '/content/drive/MyDrive/plants_classification/models/resnet50_ovr_turczaninovii.pth'\n",
        "model_hybrid_path = '/content/drive/MyDrive/plants_classification/models/resnet50_ovr_hybrid.pth'"
      ],
      "metadata": {
        "id": "7iiJNHgkVzys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_multi = make_model(model_multifida_path)\n",
        "model_turcz = make_model(model_turczaninovii_path)\n",
        "model_hybrid = make_model(model_hybrid_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDAisp5LVUnE",
        "outputId": "4c832898-d05a-4ef0-8ba9-6aad71f672e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 89.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visual_map = {64: (8, 8),\n",
        "              128: (16, 8),\n",
        "              256: (16, 16),\n",
        "              512: (32, 16),\n",
        "              1024: (32, 32),\n",
        "              2048: (64, 32)}"
      ],
      "metadata": {
        "id": "5EF0K-uiXajn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_imgs_for_gif(name_v, image_path, save_path, model):\n",
        "  def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        layer_activations[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "  global visual_map\n",
        "  image = Image.open(image_path)\n",
        "\n",
        "  fig, ax = plt.subplots()  # Создаем фигуру и оси один раз\n",
        "  ax.imshow(image)\n",
        "  ax.axis('off')\n",
        "  ax.set_title(f'Source image. P. {name_v}')\n",
        "  fig.savefig(save_path + 'source.jpg')  # Сохраняем фигуру\n",
        "  ax.clear() # Очищаем оси для следующего фильтра\n",
        "  plt.close(fig)\n",
        "\n",
        "  chosen_layers = make_layers(model)\n",
        "\n",
        "  input_batch = preprocess_image(image_path)\n",
        "  layer_activations = {}\n",
        "\n",
        "  for pair in chosen_layers:\n",
        "    pair['layer'].register_forward_hook(get_activation(pair['name']))\n",
        "\n",
        "  with torch.no_grad():\n",
        "      output = model(input_batch)\n",
        "\n",
        "  for pair in chosen_layers:\n",
        "    activations = layer_activations[pair['name']]\n",
        "    path = save_path + f'{pair[\"name\"]} filter_{1}.jpg'\n",
        "    num_filters = activations.shape[1]\n",
        "    fig, ax = plt.subplots()  # Создаем фигуру и оси один раз\n",
        "    ax.imshow(activations[0, 0].cpu().numpy(), cmap='gray')\n",
        "    ax.axis('off')\n",
        "    ax.set_title(pair['name'] + f' Filter {1}')\n",
        "    fig.savefig(path)  # Сохраняем фигуру\n",
        "    ax.clear() # Очищаем оси для следующего фильтра\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "j9rTIXTseHbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names_n_imgs = (('turczaninovii', turczaninovii_imgs[3], model_turcz)\n",
        "                # (('multifida', multifida_imgs[7], model_multi),\n",
        "\n",
        "                # ('hybrid', hybrid_imgs[3], model_hybrid))"
      ],
      "metadata": {
        "id": "za0cDtAnUVJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "abmx5sxBfe5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name, img_path, model = 'turczaninovii', '/content/turcz_bin (1).jpg', model_turcz\n",
        "save_path = f'/content/drive/MyDrive/plants_classification/cnn_imgs/{name}/'\n",
        "make_imgs_for_gif(name, img_path, save_path, model)\n",
        "get_grad_cam(name, img_path, f'/content/drive/MyDrive/plants_classification/grad_cam_results/{name}_RES.jpg', model)\n",
        "\n"
      ],
      "metadata": {
        "id": "FXhDvZjQW3iD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e42233-6e2a-47db-bce9-49711c7f6574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вероятность принадлежности экземпляра к P. turczaninovii: 0.241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rtBnQ7CRHrXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grad-Cam"
      ],
      "metadata": {
        "id": "JEuplG5AUj3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get_grad_cam(test_multifida[i], f'/content/drive/MyDrive/plants_classification/grad_cam_results/multifida_RES.jpg')\n",
        "# get_grad_cam(test_turczaninovii[i], f'/content/drive/MyDrive/plants_classification/grad_cam_results/turczaninovii_RES.jpg')"
      ],
      "metadata": {
        "id": "zyJHxWVEapIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h2AmKqGUcGq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# # ----------------------------------------------------------------------\n",
        "# # 3. Define Transformations\n",
        "# # ----------------------------------------------------------------------\n",
        "\n",
        "# # Define image transformations, including resizing\n",
        "# image_size = (224, 224)  # Grad-CAM often works best with a fixed size\n",
        "\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize(image_size),  # Resize the image\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "# ])\n",
        "\n",
        "# targets = [ClassifierOutputSoftmaxTarget(1)]\n",
        "# # fix the target layer (after which we'd like to generate the CAM)\n",
        "# target_layers = [model.layer4]\n",
        "# cam = GradCAM(model=model, target_layers=target_layers) # Ensure CUDA is used if available\n",
        "\n",
        "\n",
        "\n",
        "# print(input_tensor.size())\n",
        "# # generate CAM\n",
        "# grayscale_cams = cam(input_tensor=input_tensor, targets=targets)\n",
        "# cam_image = show_cam_on_image(np.float32(img)/255, grayscale_cams[0, :], use_rgb=True) # Convert PIL Image to numpy array and normalize\n",
        "# cam_image = np.uint8(255 * cam_image)  # Convert back to uint8\n",
        "\n",
        "# cam = np.uint8(255*grayscale_cams[0, :])\n",
        "# cam = cv2.merge([cam, cam, cam])\n",
        "\n",
        "# # Convert PIL Image to numpy array\n",
        "# img_np = np.array(img)\n",
        "\n",
        "# # Resize cam_image to match the dimensions of img_np\n",
        "# cam_image_resized = cv2.resize(cam_image, (img_np.shape[1], img_np.shape[0])) # (width, height)\n",
        "\n",
        "# # display the original image & the associated CAM\n",
        "# images = np.hstack((img_np, cam_image_resized))\n",
        "# final_image = PIL.Image.fromarray(images)\n",
        "# final_image.show() # Or save it"
      ],
      "metadata": {
        "id": "2KItrE6eCEga"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}